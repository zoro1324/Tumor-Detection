# ============================================================================
# Brain Tumor Detection Configuration
# ViT/Swin Transformer with Federated Learning
# ============================================================================

# Data Configuration
data:
  dataset_path: "dataset"  # Relative path from project root
  classes: ["glioma", "healthy", "meningioma", "pituitary"]
  num_classes: 4
  
  # Image preprocessing
  image_size: 224  # 224 for ViT-Base/Swin-Tiny, 384 for larger models
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet stats (converted to RGB)
  normalize_std: [0.229, 0.224, 0.225]
  apply_clahe: true  # Contrast Limited Adaptive Histogram Equalization
  clahe_clip_limit: 2.0
  clahe_tile_grid_size: [8, 8]
  
  # Data splits
  train_ratio: 0.70
  val_ratio: 0.15
  test_ratio: 0.15
  random_seed: 42

# Data Augmentation
augmentation:
  train:
    horizontal_flip: 0.5
    vertical_flip: 0.3
    rotation_limit: 15
    shift_scale_rotate:
      shift_limit: 0.1
      scale_limit: 0.1
      rotate_limit: 15
      p: 0.5
    brightness_contrast:
      brightness_limit: 0.2
      contrast_limit: 0.2
      p: 0.5
    gaussian_noise:
      var_limit: [10.0, 50.0]
      p: 0.3
  val:
    # Minimal augmentation for validation
    enabled: false
  test:
    # No augmentation for test
    enabled: false

# Model Configuration
model:
  architecture: "vit_base_patch16_224"  # Options: vit_base_patch16_224, swin_tiny_patch4_window7_224, swin_base_patch4_window7_224
  pretrained: true
  freeze_backbone: false  # Set to true for transfer learning with frozen backbone
  dropout: 0.1

# Training Configuration
training:
  batch_size: 32
  num_epochs: 50
  learning_rate: 0.0001
  weight_decay: 0.0001
  optimizer: "adamw"  # Options: adam, adamw, sgd
  
  # Learning rate scheduling
  lr_scheduler: "cosine"  # Options: cosine, step, plateau, none
  lr_warmup_epochs: 5
  lr_min: 0.000001
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001
  
  # Mixed precision training
  mixed_precision: true
  
  # Gradient clipping
  grad_clip: 1.0
  
  # Label smoothing
  label_smoothing: 0.1

# Federated Learning Configuration
federated:
  enabled: true
  num_clients: 4
  num_rounds: 100
  fraction_fit: 1.0  # Fraction of clients to sample for training (1.0 = all clients)
  fraction_evaluate: 1.0  # Fraction of clients to sample for evaluation
  
  # Client configuration
  local_epochs: 5  # Number of epochs each client trains per round
  min_fit_clients: 4  # Minimum clients for training
  min_available_clients: 4  # Minimum clients that must connect
  
  # Data distribution
  distribution_type: "iid"  # Options: iid, non_iid
  # For non-IID: each client gets different class distributions
  non_iid_alpha: 0.5  # Dirichlet distribution parameter (lower = more heterogeneous)
  
  # Privacy (optional - experimental)
  differential_privacy:
    enabled: false
    noise_multiplier: 0.1
    max_grad_norm: 1.0

# Paths
paths:
  checkpoints_dir: "checkpoints"
  logs_dir: "logs"
  results_dir: "results"
  tensorboard_dir: "logs/tensorboard"

# Logging
logging:
  use_tensorboard: true
  use_wandb: false  # Set to true if using Weights & Biases
  wandb_project: "brain-tumor-detection"
  wandb_entity: null  # Your W&B username
  log_interval: 10  # Log every N batches
  save_best_only: true

# Hardware
hardware:
  device: "cuda"  # Options: cuda, cpu
  num_workers: 0  # DataLoader workers (set to 0 on Windows to avoid pickle issues)
  pin_memory: true

# Evaluation
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1", "auc_roc", "confusion_matrix"]
  save_predictions: true
  generate_attention_maps: true
  attention_map_samples: 20  # Number of samples for attention visualization
